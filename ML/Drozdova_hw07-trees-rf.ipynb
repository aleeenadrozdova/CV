{"cells":[{"cell_type":"markdown","metadata":{"id":"6b1Adex_-g3S"},"source":["# Интеллектуальный анализ данных – весна 2024\n","\n","# Домашнее задание 7: Деревья. Случайный лес\n","\n","Правила:\n","\n","- Домашнее задание оценивается в 10 баллов (+1 бонусный балл).\n","\n","\n","- Можно использовать без доказательства любые результаты, встречавшиеся на лекциях или семинарах по курсу, если получение этих результатов не является вопросом задания.\n","\n","\n","- Можно использовать любые свободные источники с обязательным указанием ссылки на них.\n","\n","\n","- Плагиат не допускается. При обнаружении случаев списывания, 0 за работу выставляется всем участникам нарушения, даже если можно установить, кто у кого списал.\n","\n","<!-- ![](meme.jpg) -->\n","<img src=\"meme.jpg\" alt=\"Drawing\" style=\"width: 700px;\"/>"]},{"cell_type":"markdown","metadata":{"id":"l-Vr72hz-g3U"},"source":["## Часть 1: Основы построения решающие дерева (1.5 балла)\n","\n","В этой части все расчёты необходимо реализовывать в виде запрограммированных формул, например, на `numpy`. **Нельзя использовать готовые реализации**. Например, если в задании требуется рассчитать энтропию, то требуется в каком-то виде релизовать расчёт по формуле, но нельзя использовать готовую реализацию `some_module.entropy()`."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":478,"status":"ok","timestamp":1716843026878,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"},"user_tz":-180},"id":"IEKkJtL9-g3V"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"fQjSTsep-g3V"},"source":["**Задание 1.1 (0.5 балла)** Пусть известно, что в вершину решающего дерева попали 10 объектов, 8 из которых имеют метку класса $k_1$, а 2 имеют метку класса $k_2$. Рассчитайте энтропию такого распределения классов (с натуральным логарифмом). Ответ округлите до двух знаков после запятой."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1716843026878,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"},"user_tz":-180},"id":"5Hhd0vQ3-g3W","outputId":"4bf53372-9129-407d-a200-62567e237887"},"outputs":[{"output_type":"stream","name":"stdout","text":["Энтропия равна 0.5\n"]}],"source":["num = [8, 2]\n","ent = sum(map(lambda x: -x/sum(num)*np.log(x/sum(num)), num))\n","print(f'Энтропия равна {round(ent, 2)}')"]},{"cell_type":"markdown","metadata":{"id":"R-dxHpQD-g3W"},"source":["**Задание 1.2 (0.5 балла)** Пусть дополнительно известно, что вершина из предыдущего задания не является листовой и возможно такое разбиение, что в левое поддерево попадут все объекты класса $k_1$, а в правое - класса $k_2$. Посчитайте критерий информативности:\n","\n","$$\n","Q(R_m, j, t) = H(R_m) - \\frac{|R_\\ell|}{|R_m|}H(R_\\ell) - \\frac{|R_r|}{|R_m|}H(R_r),\n","$$\n","\n","где $R_m$ - множество объектов в разбиваемой вершине, $j$ - номер признака, по которому происходит разбиение, $t$ - порог разбиения, $R_\\ell$ - множество объектов в левом поддереве, $R_r$ - множество объектов в правом поддереве.\n","\n","Теперь в качестве $H(R)$ будем использовать индекс Джини:\n","\n","$$\n","H(R) = \\sum_{k=1}^J p_k(1-p_k),\n","$$\n","где $J$ – общее количество классов (в нашем случае, $J = 2$).\n","\n","Ответ округлите до двух знаков после запятой."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1716843026878,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"},"user_tz":-180},"id":"O49ZSJ4s-g3W","outputId":"e3f40d63-0a9a-4ede-cb15-4e164e3efa04"},"outputs":[{"output_type":"stream","name":"stdout","text":["Критерий информативности равен 0.32\n"]}],"source":["def gini(num):\n","  return sum(map(lambda x: x/sum(num)*(1 - x/sum(num)), num))\n","\n","Q = gini(num) - num[0]/num[1] * gini([num[0], 0]) - num[1]/num[0] * gini([0, num[1]])\n","print(f'Критерий информативности равен {round(Q, 2)}')"]},{"cell_type":"markdown","metadata":{"id":"Z-piRGLl-g3W"},"source":["**Задание 1.3 (0.5 балла)** Пусть при построении дерева образовалась листовая вершина с 10 объектами, значения целевой переменной для которых следующие: [1, 10, 5, 18, 100, 30, 50, 61, 84, 47] (решается задача регрессии). Чему будут равны предсказания модели для этих объектов?"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1716843026879,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"},"user_tz":-180},"id":"Pm4wYpLV-g3W","outputId":"0eef07da-7eef-4abc-c8d6-6c353c1c378f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Предсказание модели 40.6\n"]}],"source":["y = [1, 10, 5, 18, 100, 30, 50, 61, 84, 47]\n","print(f'Предсказание модели {np.mean(y)}')"]},{"cell_type":"markdown","metadata":{"id":"WTO10DAc-g3W"},"source":["## Часть 2: Решающие деревья (4.5 балла)\n","\n","В этой части мы напишем и протестируем собственную реализацию решающего дерева."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"2dMcpfBf-g3W","executionInfo":{"status":"ok","timestamp":1716843026879,"user_tz":-180,"elapsed":6,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"}}},"outputs":[],"source":["from collections import Counter\n","from typing import Dict, List, Tuple, Union"]},{"cell_type":"markdown","metadata":{"id":"mD1bRPSq-g3X"},"source":["**Задание 2.1 (1.5 балла)** Реализуйте функцию `find_best_split()`, которая должна находить оптимальное разбиение подмножества обучающей выборки в соответствии с информационным критерием из **Задания 1.2**. В качестве меры хаотичности $H(R)$ для задачи регрессии испольуйте дисперсию подвыборки, а для задачи классификации – критерий Джини (определён в том же задании).\n","\n","Для категориальных признаков применяется наивный алгоритм разбиения: мы пытаемся найти одно значение, разбиение по которому сильнее всего увеличит критерий информативности. Иными словами, объекты с конкретным значением признака отправляем в левое поддерево, остальные - в правое. Обратите внимание, что это далеко не оптимальные способ учёта категориальных признаков. Например, можно было бы на каждое значение категориального признака создавать отдельное поддерево или использовать более сложные подходы. Подробнее об этом можно прочитать в конспектах [лекций](https://github.com/esokolov/ml-course-hse/blob/master/2019-fall/lecture-notes/lecture07-trees.pdf) по машинному обучению на ПМИ (раздел «Учёт категориальных признаков»).\n","\n","В качестве подсказок реализации можете пользоваться кодом из бонусной части семинара по решающим деревьям.\n","\n","**Бонус:** Разрешается делать цикл для перебора порогов, но возможна имплементация без него. За имплементацию без цикла – **бонус 1 балл**."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"lRzNgUwtb82H","executionInfo":{"status":"ok","timestamp":1716843439516,"user_tz":-180,"elapsed":1027,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"}}},"outputs":[],"source":["import numpy as np\n","from typing import Union, Tuple\n","import pandas as pd\n","\n","def gini(y):\n","    \"\"\"\n","    Вычисляет критерий Джини\n","    \"\"\"\n","    # print(y)\n","    counts = np.bincount(y.astype(int))\n","    probs = counts / len(y)\n","    return 1 - np.sum(probs ** 2)\n","\n","def variance(y):\n","    \"\"\"\n","    Вычисляет дисперсию\n","    \"\"\"\n","    return np.var(y)\n","\n","def InfoCriteria(task: str,\n","                 feature_type: str,\n","                 feature_vector, # значения признака\n","                 R_m: np.array, # целевая переменная\n","                 t) -> float:\n","    \"\"\"\n","    Вычисляет критерий информативности\n","    \"\"\"\n","    q, R_l, R_r, H_m, H_l, H_r = 0, None, None, 0, 0, 0\n","\n","    if feature_type == \"categorical\":\n","        R_l = R_m[feature_vector == t]\n","        R_r = R_m[feature_vector != t]\n","    elif feature_type == \"real\":\n","        R_l = R_m[feature_vector < t]\n","        R_r = R_m[feature_vector >= t]\n","    else:\n","        raise ValueError(\"Invalid feature_type. Must be 'categorical' or 'real'.\")\n","    # print(R_m)\n","    # print(R_l)\n","    # print(R_r)\n","    if task == \"classification\":\n","        H_m, H_l, H_r = gini(R_m), gini(R_l), gini(R_r)\n","    elif task == \"regression\":\n","        H_m, H_l, H_r = variance(R_m), variance(R_l), variance(R_r)\n","    else:\n","        raise ValueError(\"Invalid task. Must be 'classification' or 'regression'.\")\n","\n","    return H_m - len(R_l)/len(R_m) * H_l - len(R_r)/len(R_m) * H_r\n","\n","import numpy as np\n","\n","def CountThresholds(feature_vector, feature_type):\n","    thres = np.unique(feature_vector)\n","    if feature_type == \"categorical\":\n","        return thres\n","    else:\n","        mid_points = (thres[:-1] + thres[1:]) / 2\n","        return mid_points\n","\n","def find_best_split(\n","    feature_vector: np.ndarray,\n","    target_vector: np.ndarray,\n","    task: str = \"classification\",\n","    feature_type: str = \"real\"\n","):\n","    \"\"\"\n","    Указания:\n","    * Пороги, приводящие к попаданию в одно из поддеревьев пустого множества объектов, не рассматриваются.\n","    * В качестве порогов, нужно брать среднее двух сосдених (при сортировке) значений признака\n","    * Поведение функции в случае константного признака может быть любым.\n","    * При одинаковых приростах Джини или дисперсии нужно выбирать минимальный сплит.\n","    * За наличие в функции циклов балл будет снижен. Векторизуйте! :)\n","\n","    :param feature_vector: вещественнозначный вектор значений признака\n","    :param target_vector: вектор классов объектов,  len(feature_vector) == len(target_vector)\n","    :param task: либо `classification`, либо `regression`\n","    :param feature_type: либо `real`, либо `categorical`\n","\n","    :return thresholds: отсортированный по возрастанию вектор со всеми возможными порогами, по которым объекты можно\n","     разделить на две различные подвыборки, или поддерева\n","    :return ginis: вектор со значениями критерия Джини для каждого из порогов в thresholds len(ginis) == len(thresholds)\n","    :return threshold_best: оптимальный порог (число)\n","    :return gini_best: оптимальное значение критерия Джини (число)\n","    \"\"\"\n","    thresholds = CountThresholds(feature_vector, feature_type)\n","    vectorized_create_q_value = np.vectorize(InfoCriteria, excluded=[0,1,2,3])\n","    # print(feature_vector)\n","    # print(thresholds)\n","    # print(target_vector)\n","    # Применяем vectorized функцию к массиву thresholds\n","    q_values = vectorized_create_q_value(task,feature_type, feature_vector, target_vector, thresholds)\n","\n","    # q_values = np.vectorize(InfoCriteria)(task, feature_type, feature_vector, target_vector, thresholds)\n","    q_optim = np.max(q_values)\n","    t_optim = thresholds[np.argmax(q_values)]\n","    return thresholds, q_values, t_optim, q_optim"]},{"cell_type":"markdown","metadata":{"id":"qb6rYNDp-g3X"},"source":["Эту функцию можно протестировать на датасете `California`."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"dko34S0E-g3X","executionInfo":{"status":"ok","timestamp":1716843443624,"user_tz":-180,"elapsed":1567,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"}}},"outputs":[],"source":["from sklearn.datasets import fetch_california_housing"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"pbxyvnlE-g3X","colab":{"base_uri":"https://localhost:8080/","height":339},"executionInfo":{"status":"error","timestamp":1716843444734,"user_tz":-180,"elapsed":1117,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"}},"outputId":"bfef58f2-c470-4f97-9ed3-2dffcdeefa4f"},"outputs":[{"output_type":"error","ename":"HTTPError","evalue":"HTTP Error 403: Forbidden","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-166f2f61f69f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_california_housing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feature_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_california_housing.py\u001b[0m in \u001b[0;36mfetch_california_housing\u001b[0;34m(data_home, download_if_missing, return_X_y, as_frame)\u001b[0m\n\u001b[1;32m    136\u001b[0m         )\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0marchive_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fetch_remote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mARCHIVE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_home\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r:gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marchive_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_base.py\u001b[0m in \u001b[0;36m_fetch_remote\u001b[0;34m(remote, dirname)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1324\u001b[0;31m     \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m     \u001b[0mchecksum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sha256\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecksum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mchecksum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"]}],"source":["data = fetch_california_housing()\n","X = pd.DataFrame(data=data[\"data\"], columns=data[\"feature_names\"])\n","y = data[\"target\"]\n","X.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJiaZx6S-g3X","executionInfo":{"status":"aborted","timestamp":1716843028319,"user_tz":-180,"elapsed":21,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"}}},"outputs":[],"source":["y"]},{"cell_type":"code","source":["thresholds, variances, threshold_best, variance_best = find_best_split(\n","    X[\"MedInc\"].to_numpy(),\n","    y,\n","    task=\"regression\",\n","    feature_type=\"real\"\n",")"],"metadata":{"id":"_HJ6xqFjEkPP","executionInfo":{"status":"aborted","timestamp":1716843028319,"user_tz":-180,"elapsed":20,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"unMvmsmc-g3X"},"source":["Выведите график зависимости значения критерия ошибки от порогового значения при разбиении вершины по признаку `MedInc`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8hhU74JK-g3Y","executionInfo":{"status":"aborted","timestamp":1716843028320,"user_tz":-180,"elapsed":21,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"}}},"outputs":[],"source":["plt.plot(thresholds, variances)\n","plt.title(\"Зависимость критерия ошибки от порога\")\n","plt.xlabel(\"пороговое значение\")\n","plt.ylabel(\"значение критерия информативности\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"JSVFs-_l-g3Y"},"source":["Найдите лучший, с вашей точки зрения, предикат первой вершины решающего дерева."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-XxmWpSp-g3Y","executionInfo":{"status":"aborted","timestamp":1716843028320,"user_tz":-180,"elapsed":21,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"}}},"outputs":[],"source":["threshold_best, variance_best"]},{"cell_type":"markdown","metadata":{"id":"Alx7W4f_-g3Y"},"source":["**Задание 2.2 (1 балл)** Разберитесь с написанным кодом решающего дерева, заполните пропуски в коде и реализуйте недостающий метод `_predict_node()`.\n","\n","Построение дерева осуществляется согласно базовому жадному алгоритму, предложенному в лекции в разделе «Построение дерева».\n","- **Выбор лучшего разбиения** необходимо производить по критерию Джини.\n","- **Критерий останова:** все объекты в листе относятся к одному классу или ни по одному признаку нельзя разбить выборку.\n","- **Ответ в листе:** наиболее часто встречающийся класс в листе.\n","\n","В задаче также предлагается получить два бонуса, по баллу на каждый!\n","\n","- **Реализуйте способ обрабатывать пропуски в даннх и реализуйте его, пояснив свои действия.**\n","- **Реализуйте метод оценки важности признаков.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q4tpYbu7-g3Y","executionInfo":{"status":"aborted","timestamp":1716843028320,"user_tz":-180,"elapsed":21,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"}}},"outputs":[],"source":["from sklearn.impute import SimpleImputer\n","\n","\n","class DecisionTree:\n","\n","    def __init__(\n","        self,\n","        feature_types: Union[List[str], np.ndarray],\n","        max_depth: int = None,\n","        min_samples_split: int = None,\n","        min_samples_leaf: int = None,\n","        task: str = \"classification\"\n","    ) -> None:\n","\n","        if np.any(list(map(lambda x: x != \"real\" and x != \"categorical\", feature_types))):\n","            raise ValueError(\"There is unknown feature type\")\n","\n","        # В этой переменной будем хранить узлы решающего дерева. Каждая вершина хранит в себе идентификатор того,\n","        # является ли она листовой. Листовые вершины хранят значение класса для предсказания, нелистовые - правого и\n","        # левого детей (поддеревья для продолжения процедуры предсказания)\n","        self._tree = {}\n","\n","        # типы признаков (категориальные или числовые)\n","        self._feature_types = feature_types\n","\n","        # гиперпараметры дерева\n","        self._max_depth = max_depth\n","        self._min_samples_split = min_samples_split\n","        self._min_samples_leaf = min_samples_leaf\n","        self.task = task\n","\n","        # Переменная, если вы решите делать бонус\n","        self._feature_importances = {}\n","\n","    def _handle_missing_values(self, X, feature_types):\n","        \"\"\"\n","        Заполнение пропусков\n","        Для категориальных признаков - мода признака\n","        Для числовых признаков - среднее этого признака на выборке\n","        \"\"\"\n","        imputers = []\n","        for feature_type in feature_types:\n","            if feature_type == \"real\":\n","                imputer = SimpleImputer(strategy=\"mean\")\n","            elif feature_type == \"categorical\":\n","                imputer = SimpleImputer(strategy=\"most_frequent\")\n","            else:\n","                raise ValueError(\"Unknown feature type\")\n","            imputers.append(imputer)\n","\n","        for i, imputer in enumerate(imputers):\n","            X[:, i] = imputer.fit_transform(X[:, i].reshape(-1, 1)).ravel()\n","\n","        return X\n","\n","    def feature_importances(self):\n","        importances = {}\n","        for feature in range(len(self._feature_types)):\n","            importances[feature] = self._feature_importances.get(feature, 0)\n","        return importances\n","\n","    def _fit_node(\n","        self,\n","        sub_X: np.ndarray,\n","        sub_y: np.ndarray,\n","        node: dict\n","    ) -> None:\n","\n","        # критерий останова\n","        if np.all(sub_y == sub_y[0]):\n","            node[\"type\"] = \"terminal\"\n","            node[\"class\"] = sub_y[0]\n","            return\n","\n","        feature_best, threshold_best, gini_best, split = None, None, None, None\n","        for feature in range(sub_X.shape[1]):\n","            feature_type = self._feature_types[feature]\n","            categories_map = {}\n","\n","            # подготавливаем признак для поиска оптимального порога\n","            if feature_type == \"real\":\n","                feature_vector = sub_X[:, feature]\n","            elif feature_type == \"categorical\":\n","                # здесь могла быть реализация более сложного подхода к обработке категориального признака\n","                feature_vector = sub_X[:, feature]\n","\n","            # ищем оптимальный порог\n","            # print(feature_vector)\n","            # print(sub_y)\n","            _, _, threshold, gini = find_best_split(feature_vector, sub_y, self.task, feature_type)\n","\n","            if gini_best is None or gini > gini_best:\n","                feature_best = feature\n","                gini_best = gini\n","\n","                # split - маска на объекты, которые должны попасть в левое поддерево\n","                if feature_type == \"real\":\n","                    threshold_best = threshold\n","                    split = feature_vector < threshold_best\n","                elif feature_type == \"categorical\":\n","                    # в данной реализации это просто значение категории\n","                    threshold_best = threshold\n","                    split = feature_vector == threshold_best\n","                else:\n","                    raise ValueError\n","\n","        # записываем полученные сплиты в атрибуты класса\n","        if feature_best is None:\n","            node[\"type\"] = \"terminal\"\n","            node[\"class\"] = Counter(sub_y).most_common(1)[0][0]\n","            return\n","\n","        node[\"type\"] = \"nonterminal\"\n","\n","        node[\"feature_split\"] = feature_best\n","        if self._feature_types[feature_best] == \"real\":\n","            node[\"threshold\"] = threshold_best\n","        elif self._feature_types[feature_best] == \"categorical\":\n","            node[\"category_split\"] = threshold_best\n","        else:\n","            raise ValueError\n","\n","        node[\"left_child\"], node[\"right_child\"] = {}, {}\n","        self._fit_node(sub_X[split], sub_y[split], node[\"left_child\"])\n","        self._fit_node(sub_X[np.logical_not(split)], sub_y[np.logical_not(split)], node[\"right_child\"])\n","\n","    def _predict_node(self, x: np.ndarray, node: dict) -> int:\n","        \"\"\"\n","        Предсказание начинается с корневой вершины дерева и рекурсивно идёт в левое или правое поддерево в зависимости от значения\n","        предиката на объекте. Листовая вершина возвращает предсказание.\n","        :param x: np.array, элемент выборки\n","        :param node: dict, вершина дерева\n","        \"\"\"\n","        if node[\"type\"] == \"terminal\":\n","            return node[\"class\"]\n","\n","        feature = node[\"feature_split\"]\n","        if self._feature_types[feature] == \"real\":\n","            if x[feature] <= node[\"threshold\"]:\n","                return self._predict_node(x, node[\"left_child\"])\n","            else:\n","                return self._predict_node(x, node[\"right_child\"])\n","        elif self._feature_types[feature] == \"categorical\":\n","            if x[feature] == node[\"category_split\"]:\n","                return self._predict_node(x, node[\"left_child\"])\n","            else:\n","                return self._predict_node(x, node[\"right_child\"])\n","\n","    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n","        X = self._handle_missing_values(X, self._feature_types)\n","        self._fit_node(X, y, self._tree)\n","\n","    def predict(self, X: np.ndarray) -> np.ndarray:\n","        predicted = []\n","        X = self._handle_missing_values(X, self._feature_types)\n","        for x in X:\n","            predicted.append(self._predict_node(x, self._tree))\n","\n","        return np.array(predicted)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CKJ1SiHm-g3Y"},"source":["**Задание 2.3 (1 балл)** Загрузите таблицу `students.csv` (это немного преобразованный датасет [User Knowledge](https://archive.ics.uci.edu/ml/datasets/User+Knowledge+Modeling)). В ней признаки объекта записаны в первых пяти столбцах, а в последнем записана целевая переменная (класс: 0 или 1). Постройте на одном изображении пять кривых \"порог — значение критерия Джини\" для всех пяти признаков. Отдельно визуализируйте диаграммы рассеяния \"значение признака — класс\" для всех пяти признаков."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nb-t-d-p-g3Y","executionInfo":{"status":"aborted","timestamp":1716843028320,"user_tz":-180,"elapsed":21,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"}}},"outputs":[],"source":["data = pd.read_csv('students.csv', sep=',')\n","data.head()"]},{"cell_type":"code","source":["X = pd.DataFrame(data.loc[::, 'STG':'PEG'])\n","y = data.UNS\n","\n","plt.title(\"Зависимость критерия ошибки от порога\")\n","plt.xlabel(\"пороговое значение\")\n","plt.ylabel(\"значение критерия информативности\")\n","\n","for column in X.columns:\n","    thresholds, variances, threshold_best, variance_best = find_best_split(\n","    X[column].to_numpy(),\n","    y,\n","    task=\"classification\",\n","    feature_type=\"real\")\n","\n","    plt.plot(thresholds, variances, label=column)\n","\n","plt.grid()\n","plt.legend()\n","plt.show()"],"metadata":{"id":"6ZAtk3CJOi7J","executionInfo":{"status":"aborted","timestamp":1716843028321,"user_tz":-180,"elapsed":22,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","\n","for column in X.columns:\n","    sns.scatterplot(x=X[column], y=y, color='purple' )\n","    plt.xlabel(f'Значение признака {column}')\n","    plt.ylabel(\"Класс\")\n","    plt.show()"],"metadata":{"id":"DiWoWCSpO5sz","executionInfo":{"status":"aborted","timestamp":1716843028321,"user_tz":-180,"elapsed":21,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z2lAPA__-g3Y"},"source":["Исходя из кривых значений критерия Джини, по какому признаку нужно производить деление выборки на два поддерева? Согласуется ли этот результат с визуальной оценкой диаграмм рассеяиния? Как бы охарактеризовали вид кривой для \"хороших\" признаков, по которым выборка делится почти идеально? Чем отличаются кривые для признаков, по которым деление практически невозможно?"]},{"cell_type":"markdown","source":["Максимальное значение критерия Джини (критерия информативности) достигается при использовании признака PEG.\n","Это согласуется с диаграммой рассеивания, так как наблюдается достаточно четкая граница между значением признака PEG и классом (визуально PEG < 0.4 => класс 0, иначен клас 1)\n","\n","Если график критерия информативности приближен к горизонтальной прямой, то невозможно определить какой порог будет оптимальным, поэтому практически невозможно разделить выборку по признакам\n","И наоборот, кривая для хороших признаков стремится к параболе, то есть чётко виден максимум критерия Джини и легко определяется порог"],"metadata":{"id":"FWx8vxZIPVU7"}},{"cell_type":"markdown","metadata":{"id":"Gn7T-B1Y-g3Z"},"source":["**Задание 2.4 (1 балл)** Протестируйте свое решающее дерево на датасете [mushrooms](https://archive.ics.uci.edu/ml/datasets/Mushroom).\n","\n","1. Скачайте таблицу `agaricus-lepiota.data` (из [Data Folder](https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/)),\n","2. Считайте таблицу при помощи `pandas`,\n","3. Примените к каждому столбцу `LabelEncoder` (из `sklearn`), чтобы преобразовать строковые имена категорий в натуральные числа.\n","\n","Первый столбец — это целевая переменная (e — edible, p — poisonous) Мы будем измерять качество с помощью accuracy, так что нам не очень важно, что будет классом 1, а что — классом 0. Обучите решающее дерево на половине случайно выбранных объектов (признаки в датасете категориальные) и сделайте предсказания для оставшейся половины. Вычислите accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NUW1QsqD-g3Z","executionInfo":{"status":"aborted","timestamp":1716843028321,"user_tz":-180,"elapsed":21,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"}}},"outputs":[],"source":["!wget https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\n","\n","data = pd.read_csv('agaricus-lepiota.data', sep=',')\n","data.head()"]},{"cell_type":"code","source":["from sklearn import preprocessing\n","le = preprocessing.LabelEncoder()\n","data = data.apply(le.fit_transform)\n","\n","X = data.drop(columns='p')\n","y = data['p']\n","X.head()"],"metadata":{"id":"vi5FbMvFVoIA","executionInfo":{"status":"aborted","timestamp":1716843028321,"user_tz":-180,"elapsed":21,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y.head()"],"metadata":{"id":"3pboPHuXqfSX","executionInfo":{"status":"aborted","timestamp":1716843028321,"user_tz":-180,"elapsed":21,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y,\n","                                                    test_size=0.5,\n","                                                    random_state=10)\n","from sklearn.metrics import accuracy_score\n","feature_types = np.full(X.shape[1], \"categorical\")\n","dt = DecisionTree(feature_types, task=\"classification\")\n","dt.fit(X_train.to_numpy(), y_train.to_numpy())\n","score = accuracy_score(y_test, dt.predict(X_test.to_numpy()))\n","\n","print(f'Accuracy = {score}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"MmS9D8jqVLgZ","executionInfo":{"status":"error","timestamp":1716843067511,"user_tz":-180,"elapsed":498,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"}},"outputId":"194e3371-e852-405d-8ac6-6e2141146250"},"execution_count":9,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'X' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-84eff2a3eee6>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m X_train, X_test, y_train, y_test = train_test_split(X, y, \n\u001b[0m\u001b[1;32m      4\u001b[0m                                                     \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                     random_state=10)\n","\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"dsUxprIf-g3Z"},"source":["## Часть 3: Бэггинг и случайный лес (4 балла)"]},{"cell_type":"markdown","metadata":{"id":"GS-kUChI-g3Z"},"source":["В данной части мы будем работать [с задачей предсказания диабета у пациента](https://www.kaggle.com/uciml/pima-indians-diabetes-database/data). Посмотрим на работу бэггинга над решающими деревьями и случайного леса, сравним их работу."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5aH-bCP6-g3Z","executionInfo":{"status":"aborted","timestamp":1716843428112,"user_tz":-180,"elapsed":4,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"}}},"outputs":[],"source":["from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":351302,"status":"aborted","timestamp":1716843428113,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"},"user_tz":-180},"id":"idi_vmQT-g3Z","scrolled":true},"outputs":[],"source":["data = pd.read_csv('diabetes.csv')\n","print(f\"Dataset shape: {data.shape}\")\n","data.head()"]},{"cell_type":"markdown","metadata":{"id":"34g2V-xD-g3Z"},"source":["Посмотрим на распределение целевой переменной"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":351296,"status":"aborted","timestamp":1716843428114,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"},"user_tz":-180},"id":"0CeJ80Gv-g3Z"},"outputs":[],"source":["data['Outcome'].hist()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"HQ7T15Y2-g3Z"},"source":["**Задание 3.1 (0.5 балла)** Разделите данные на признаки и целевую переменную. Разбейте датасет на обучающую и тестовую части в отношении 7:3. Затем разделите обучающую выборку на обучающую-обучающую и обучающую-валидационную в соотношении 7:3 (то есть в итоге должно получиться три выборки: обучающая-обучающая (0.49 от исходного датасета), обучающая-валидационная (0.21 от исходного датасета) и тестовая (0.3 от исходного датасета)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8YuEv3y4-g3Z","executionInfo":{"status":"aborted","timestamp":1716843428114,"user_tz":-180,"elapsed":351289,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"}}},"outputs":[],"source":["X = data.drop('Outcome', axis=1)\n","y = data['Outcome']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n","X_train_train, X_validate, y_train_train, y_validate = train_test_split(X_train, y_train, test_size=0.3, random_state=10)"]},{"cell_type":"markdown","metadata":{"id":"t7unaWE3-g3a"},"source":["**Задание 3.2 (1 балл)** На обучающей-валидационной выборке подберите оптимальные значения гиперпараметров `max_depth` и `min_samples_leaf` для `DecisionTreeClassifier`. Для этого:\n","1. Создайте списки с возможными значениями для перебора.\n","2. Для каждой пары значений обучите дерево на обучающей-обучающей выборке и определите качество на обучающей-валидационной выборке. В качестве критерия будем использовать `f1-меру`.\n","3. Выберите ту пару значений, которая даёт наилучшее качество на обучающей-валидационной выборке.\n","\n","\n","Обучите решающее дерево с подобранными гиперпараметрами на **полной обучающей** выборке. Оцените качество классификации на тестовой выборке по метрикам `accuracy`, `precision` и `recall`, `auc_roc`."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":351270,"status":"aborted","timestamp":1716843428115,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"},"user_tz":-180},"id":"32S_I0WTpvcW"},"outputs":[],"source":["score = 0\n","perfect_leaf = None\n","perfect_depth = None\n","for depth in max_depth_array:\n","    for leaf in min_samples_leaf_array:\n","        dt = DecisionTreeClassifier(max_depth=depth, min_samples_leaf=leaf, random_state=13)\n","        dt.fit(X_train_train, y_train_train)\n","        new_score = f1_score(y_validate, dt.predict(X_validate))\n","        if new_score > score:\n","            score = new_score\n","            perfect_depth = depth\n","            perfect_leaf = leaf\n","print(f'max_depth = {perfect_depth}, min_samples_leaf = {perfect_leaf}, score = {score}')"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"elapsed":8608,"status":"ok","timestamp":1716843080555,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"},"user_tz":-180},"id":"xNBNu5_n-6G4","outputId":"803a75a8-0729-432c-aa64-f2e3dc348e42"},"outputs":[{"output_type":"stream","name":"stdout","text":["max_depth = 7, min_samples_leaf = 15, score = 0.6721311475409836\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import seaborn as sns\n","max_depth_array = range(1, 30)\n","min_samples_leaf_array = range(1, 30)\n","\n","score_arr = np.zeros((len(max_depth_array), len(min_samples_leaf_array)), dtype=float)\n","for i in range(len(max_depth_array)):\n","    for j in range(len(min_samples_leaf_array)):\n","        dt = DecisionTreeClassifier(max_depth=max_depth_array[i], min_samples_leaf=min_samples_leaf_array[j], random_state=10)\n","        dt.fit(X_train_train, y_train_train)\n","        score_arr[i][j] = f1_score(y_validate, dt.predict(X_validate))\n","score_arr\n","\n","sns.heatmap(score_arr, xticklabels=max_depth_array, yticklabels=min_samples_leaf_array)\n","\n","score_arr = np.array(score_arr)\n","\n","max_depth = max_depth_array[np.where(score_arr == np.max(score_arr))[0][0]]\n","min_samples_leaf = min_samples_leaf_array[np.where(score_arr == np.max(score_arr))[1][0]]\n","print(f'max_depth = {max_depth}, min_samples_leaf = {min_samples_leaf}, score = {np.max(score_arr)}')"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1716843080556,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"},"user_tz":-180},"id":"9TEIcM5MhbwL","outputId":"756eef7e-2a78-4a66-86d0-f2233c2d6b3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy = 0.7229437229437229\n","Precision = 0.6455696202531646\n","Recall = 0.5862068965517241\n","AUC-ROC = 0.6958812260536399\n"]}],"source":["from sklearn import metrics\n","\n","dt = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=10)\n","dt.fit(X_train, y_train)\n","pred = dt.predict(X_test)\n","\n","print(f\"Accuracy = {metrics.accuracy_score(y_test, pred)}\")\n","print(f\"Precision = {metrics.precision_score(y_test, pred)}\")\n","print(f\"Recall = {metrics.recall_score(y_test, pred)}\")\n","print(f\"AUC-ROC = {metrics.roc_auc_score(y_test, pred)}\")"]},{"cell_type":"markdown","metadata":{"id":"8c3jBQWt-g3a"},"source":["**Задание 3.3 (0.5 балла)** Обучите [`BaggingClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) на 50 деревьях на **полной обучающей** выборке. Оцените качество классификации на тестовой выборке по тем же метрикам."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":412,"status":"ok","timestamp":1716843080959,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"},"user_tz":-180},"id":"a7ju8sAt-g3a","outputId":"abd092ac-60e8-4030-bb8c-2dc7c8b38e1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy = 0.7705627705627706\n","Precision = 0.7931034482758621\n","Recall = 0.5287356321839081\n","AUC-ROC = 0.7227011494252873\n"]}],"source":["clf = BaggingClassifier(n_estimators=50, random_state=10)\n","clf.fit(X_train, y_train)\n","pred = clf.predict(X_test)\n","\n","print(f\"Accuracy = {metrics.accuracy_score(y_test, pred)}\")\n","print(f\"Precision = {metrics.precision_score(y_test, pred)}\")\n","print(f\"Recall = {metrics.recall_score(y_test, pred)}\")\n","print(f\"AUC-ROC = {metrics.roc_auc_score(y_test, pred)}\")"]},{"cell_type":"markdown","metadata":{"id":"Ly3iROCI-g3a"},"source":["**Задание 3.4 (1 балл)** Выполните кросс-валидацию на полной обучающей выборке и подберите оптимальные значения гиперпараметров `max_depth` и `min_samples_split` для `Random Forest` с 50 деревьями. Для этого:\n","\n","1. Создайте списки с возможными значениями для перебора.\n","2. Для каждой пары значений проведите кросс-валидацию на полной обучающей выборке. Количество разбиений выберите на ваш вкус. В качестве критерия будем использовать `f1-меру`. Усредните значение критерия по всем прогонам кросс-валидации.\n","3. Выберите ту пару значений, которая даёт наилучшее среднее качество.\n","\n","Обучите случайный лес с подобранными гиперпараметрами на **полной обучающей** выборке. Оцените качество классификации по тем же метрикам. Какая из трёх построенных моделей показала себя лучше?"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"elapsed":347156,"status":"error","timestamp":1716843428110,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"},"user_tz":-180},"id":"fAnF-bx6-g3a","outputId":"c46698dc-3c77-4062-906c-a5e75dee2a25"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-8f2ca0fd9240>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_samples_split_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_depth_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_samples_split_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mcv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mscore_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mscore_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_MultimetricScorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mScore\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mapplied\u001b[0m \u001b[0mto\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0mon\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         return self._score(\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cached_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \"\"\"\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod_caller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             return self._sign * self._score_func(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;34m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m         \"\"\"\n\u001b[0;32m--> 820\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    871\u001b[0m         ]\n\u001b[1;32m    872\u001b[0m         \u001b[0mlock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m         Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(\n\u001b[0m\u001b[1;32m    874\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_accumulate_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_accumulate_prediction\u001b[0;34m(predict, X, out, lock)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mcomplains\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mthere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \"\"\"\n\u001b[0;32m--> 650\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from sklearn.model_selection import cross_validate\n","\n","max_depth_array = range(1, 30)\n","min_samples_split_array = range(2, 30)\n","\n","score_arr = np.zeros((len(max_depth_array), len(min_samples_split_array)), dtype=float)\n","for i in range(len(max_depth_array)):\n","    for j in range(len(min_samples_split_array)):\n","        model = RandomForestClassifier(n_estimators=50, max_depth=max_depth_array[i], min_samples_split=min_samples_split_array[j], random_state=10)\n","        cv_results = cross_validate(model, X_train, y_train, scoring='f1', cv=3)\n","        score_arr[i][j] = np.mean(cv_results['test_score'])\n","score_arr\n","\n","sns.heatmap(score_arr, xticklabels=max_depth_array, yticklabels=min_samples_split_array)\n","\n","score_arr = np.array(score_arr)\n","\n","max_depth = max_depth_array[np.where(score_arr == np.max(score_arr))[0][0]]\n","min_samples_split = min_samples_split_array[np.where(score_arr == np.max(score_arr))[1][0]]\n","print(f'max_depth = {max_depth}, min_samples_split = {min_samples_split}, score = {np.max(score_arr)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1716843428111,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"},"user_tz":-180},"id":"ww1LELi5koG8"},"outputs":[],"source":["best_forest = RandomForestClassifier(n_estimators=50, max_depth=max_depth, min_samples_split=min_samples_split, random_state=10)\n","\n","best_forest.fit(X_train, y_train)\n","pred = best_forest.predict(X_test)\n","\n","print(f\"Accuracy = {metrics.accuracy_score(y_test, pred)}\")\n","print(f\"Precision = {metrics.precision_score(y_test, pred)}\")\n","print(f\"Recall = {metrics.recall_score(y_test, pred)}\")\n","print(f\"AUC-ROC = {metrics.roc_auc_score(y_test, pred)}\")"]},{"cell_type":"markdown","metadata":{"id":"D0OGN7VGmXIS"},"source":["BaggingClassifier - лучшая из трёх"]},{"cell_type":"markdown","metadata":{"id":"tFd_gEbn-g3a"},"source":["**Задание 3.5 (0.5 балла)** Постройте график зависимости AUC ROC на тестовой выборке от числа деревьев (`n_estimators`) для случайного леса, обучаемого на **полной обучающей** выборке. Какие выводы можно сделать?"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1716843428111,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"},"user_tz":-180},"id":"R97WfM1v-g3b"},"outputs":[],"source":["n_estimators_array = range(1, 500, 5)\n","auc_roc_array = []\n","\n","for n_estimators in n_estimators_array:\n","    dt = RandomForestClassifier(n_estimators=n_estimators, random_state=10)\n","\n","    dt.fit(X_train, y_train)\n","    auc_roc_array.append(metrics.roc_auc_score(y_test, dt.predict(X_test)))\n","\n","plt.plot(n_estimators_array, auc_roc_array)\n","plt.title(\"Dependence of AUC ROC on n_estimators\")\n","plt.xlabel(\"n_estimators\")\n","plt.ylabel(\"AUC ROC\")\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"XpKwDrjx-g3b"},"source":["**Задание 3.6 (0.5 балла)** Для лучшей модели случайного леса из **Задания 3.4** посчитайте важность признаков и постройте bar plot. Какой признак оказался самым важным для определения диабета?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fm6svAA7-g3b","executionInfo":{"status":"aborted","timestamp":1716843428112,"user_tz":-180,"elapsed":5,"user":{"displayName":"Алёна Дроздова","userId":"08253493550997889843"}}},"outputs":[],"source":["plt.figure(figsize=(15,8))\n","\n","sns.set_theme(style=\"whitegrid\")\n","sns.barplot(x=X.columns, y=best_forest.feature_importances_)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}